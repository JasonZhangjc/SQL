{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da020526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from time import time\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"sql-bigquery-331719-5129dc99895e.json\"\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "def show_amount_of_data_scanned(query):\n",
    "    # dry_run lets us see how much data the query uses without running it\n",
    "    dry_run_config = bigquery.QueryJobConfig(dry_run=True)\n",
    "    query_job = client.query(query, job_config=dry_run_config)\n",
    "    print('Data processed: {} GB'.format(round(query_job.total_bytes_processed / 10**9, 3)))\n",
    "    \n",
    "def show_time_to_run(query):\n",
    "    time_config = bigquery.QueryJobConfig(use_query_cache=False)\n",
    "    start = time()\n",
    "    query_result = client.query(query, job_config=time_config).result()\n",
    "    end = time()\n",
    "    print('Time to run: {} seconds'.format(round(end-start, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f646ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed: 2623.284 GB\n",
      "Data processed: 2.466 GB\n"
     ]
    }
   ],
   "source": [
    "star_query = \"SELECT * FROM `bigquery-public-data.github_repos.contents`\"\n",
    "show_amount_of_data_scanned(star_query)\n",
    "\n",
    "basic_query = \"SELECT size, binary FROM `bigquery-public-data.github_repos.contents`\"\n",
    "show_amount_of_data_scanned(basic_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84b9a8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed: 0.076 GB\n",
      "Data processed: 0.06 GB\n"
     ]
    }
   ],
   "source": [
    "more_data_query = \"\"\"\n",
    "                  SELECT MIN(start_station_name) AS start_station_name,\n",
    "                      MIN(end_station_name) AS end_station_name,\n",
    "                      AVG(duration_sec) AS avg_duration_sec\n",
    "                  FROM `bigquery-public-data.san_francisco.bikeshare_trips`\n",
    "                  WHERE start_station_id != end_station_id \n",
    "                  GROUP BY start_station_id, end_station_id\n",
    "                  LIMIT 10\n",
    "                  \"\"\"\n",
    "show_amount_of_data_scanned(more_data_query)\n",
    "\n",
    "less_data_query = \"\"\"\n",
    "                  SELECT start_station_name,\n",
    "                      end_station_name,\n",
    "                      AVG(duration_sec) AS avg_duration_sec                  \n",
    "                  FROM `bigquery-public-data.san_francisco.bikeshare_trips`\n",
    "                  WHERE start_station_name != end_station_name\n",
    "                  GROUP BY start_station_name, end_station_name\n",
    "                  LIMIT 10\n",
    "                  \"\"\"\n",
    "show_amount_of_data_scanned(less_data_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "addfee7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run: 12.604 seconds\n",
      "Time to run: 4.269 seconds\n"
     ]
    }
   ],
   "source": [
    "big_join_query = \"\"\"\n",
    "                 SELECT repo,\n",
    "                     COUNT(DISTINCT c.committer.name) as num_committers,\n",
    "                     COUNT(DISTINCT f.id) AS num_files\n",
    "                 FROM `bigquery-public-data.github_repos.commits` AS c,\n",
    "                     UNNEST(c.repo_name) AS repo\n",
    "                 INNER JOIN `bigquery-public-data.github_repos.files` AS f\n",
    "                     ON f.repo_name = repo\n",
    "                 WHERE f.repo_name IN ( 'tensorflow/tensorflow', 'facebook/react', 'twbs/bootstrap', 'apple/swift', 'Microsoft/vscode', 'torvalds/linux')\n",
    "                 GROUP BY repo\n",
    "                 ORDER BY repo\n",
    "                 \"\"\"\n",
    "show_time_to_run(big_join_query)\n",
    "\n",
    "small_join_query = \"\"\"\n",
    "                   WITH commits AS\n",
    "                   (\n",
    "                   SELECT COUNT(DISTINCT committer.name) AS num_committers, repo\n",
    "                   FROM `bigquery-public-data.github_repos.commits`,\n",
    "                       UNNEST(repo_name) as repo\n",
    "                   WHERE repo IN ( 'tensorflow/tensorflow', 'facebook/react', 'twbs/bootstrap', 'apple/swift', 'Microsoft/vscode', 'torvalds/linux')\n",
    "                   GROUP BY repo\n",
    "                   ),\n",
    "                   files AS \n",
    "                   (\n",
    "                   SELECT COUNT(DISTINCT id) AS num_files, repo_name as repo\n",
    "                   FROM `bigquery-public-data.github_repos.files`\n",
    "                   WHERE repo_name IN ( 'tensorflow/tensorflow', 'facebook/react', 'twbs/bootstrap', 'apple/swift', 'Microsoft/vscode', 'torvalds/linux')\n",
    "                   GROUP BY repo\n",
    "                   )\n",
    "                   SELECT commits.repo, commits.num_committers, files.num_files\n",
    "                   FROM commits \n",
    "                   INNER JOIN files\n",
    "                       ON commits.repo = files.repo\n",
    "                   ORDER BY repo\n",
    "                   \"\"\"\n",
    "\n",
    "show_time_to_run(small_join_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
